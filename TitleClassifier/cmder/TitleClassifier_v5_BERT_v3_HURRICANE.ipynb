{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adea2ca6-5b37-47f4-8a09-59014346c9e4",
   "metadata": {},
   "source": [
    "# Initializtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cbeaa51-31ed-418d-be12-667d10a128ae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [SOC18_DOC, SOC18_DMT]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [SOC18_DOC, SOC18_DMT]\n",
      "Index: []\n",
      "Train size: 5216\n",
      "Validation size: 652\n",
      "Test size: 652\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Read in the data\n",
    "df = pd.read_csv('C://Offline_Storage//radiantClass//All_DOC-and-DMT_data.csv')\n",
    "\n",
    "# Optional: Data cleaning\n",
    "# Retain commas, and convert to lowercase\n",
    "df['SOC18_DMT'] = df['SOC18_DMT'].str.lower().str.replace('[^a-z0-9,\\s]', '')\n",
    "\n",
    "# Instantiate the encoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the labels to produce integer encoded labels\n",
    "encoded_labels = encoder.fit_transform(df['SOC18_DOC'].values)\n",
    "\n",
    "# Convert to PyTorch tensor\n",
    "labels = torch.tensor(encoded_labels)\n",
    "\n",
    "\n",
    "# Load BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', use_pt=True)\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=864)\n",
    "\n",
    "# Check for non-string rows\n",
    "non_string_rows = df[df['SOC18_DMT'].apply(lambda x: not isinstance(x, str))]\n",
    "print(non_string_rows)\n",
    "\n",
    "# Check for NaN in 'SOC18_DMT' column\n",
    "print(df[df['SOC18_DMT'].isna()])\n",
    "\n",
    "# Drop NaN rows\n",
    "df = df.dropna(subset=['SOC18_DMT'])\n",
    "\n",
    "# Splitting the dataset 80-10-10\n",
    "train, temp = train_test_split(df, test_size=0.20, random_state=42)\n",
    "valid, test = train_test_split(temp, test_size=0.50, random_state=42)\n",
    "\n",
    "# Split data without stratifying\n",
    "train_texts, temp_texts, train_labels, temp_labels = train_test_split(\n",
    "    df['SOC18_DMT'].tolist(), encoded_labels, test_size=0.2\n",
    ")\n",
    "\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(\n",
    "    temp_texts, temp_labels, test_size=0.5\n",
    ")\n",
    "\n",
    "# Tokenize the data for each split\n",
    "train_encodings = tokenizer(train_texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "val_encodings = tokenizer(val_texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "test_encodings = tokenizer(test_texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# Convert labels for each split to torch tensors\n",
    "train_labels = torch.tensor(train_labels).long()\n",
    "val_labels = torch.tensor(val_labels).long()\n",
    "test_labels = torch.tensor(test_labels).long()\n",
    "\n",
    "\n",
    "print(f\"Train size: {len(train_labels)}\")\n",
    "print(f\"Validation size: {len(val_labels)}\")\n",
    "print(f\"Test size: {len(test_labels)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0510defc-9460-4477-ad91-be33e2f82e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 32  # You can adjust this value based on your computer's capabilities\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_data = TensorDataset(train_encodings['input_ids'], train_encodings['attention_mask'], train_labels)\n",
    "val_data = TensorDataset(val_encodings['input_ids'], val_encodings['attention_mask'], val_labels)\n",
    "test_data = TensorDataset(test_encodings['input_ids'], test_encodings['attention_mask'], test_labels)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataloader = DataLoader(train_data, sampler=RandomSampler(train_data), batch_size=batch_size)\n",
    "val_dataloader = DataLoader(val_data, sampler=SequentialSampler(val_data), batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, sampler=SequentialSampler(test_data), batch_size=batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22a639b5-3450-4917-bba0-f265a1f1daed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "# Define the optimizer. AdamW is the Adam optimizer with weight decay fix.\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)  # You can adjust the learning rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71ebb3d3-8175-4294-b627-9de18d7dca1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to print current activity and time\n",
    "from datetime import datetime\n",
    "\n",
    "def print_activity(activity):\n",
    "    current_time = datetime.now().strftime('%I:%M %p') # This will give you time in the format '01:37 PM'\n",
    "    print(f\"Starting {activity} at {current_time}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006d4d42-84d4-48e3-b025-9e555fdc53de",
   "metadata": {},
   "source": [
    "# Load and Set to Evaluation Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a579953-9fca-438d-a748-5518cb237c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = torch.load(\"fine_tuned_model_entire.pth\")\n",
    "# Ensure the model is in evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330e275b-3f8d-435d-be35-8958a3358a55",
   "metadata": {},
   "source": [
    "# Verify that CUDA is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be304e3e-0eb6-4f50-93a3-159245b16461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Cuda available?: True! :-)\n",
      "CUDA version: 11.8\n"
     ]
    }
   ],
   "source": [
    "print(f\"Is Cuda available?: {torch.cuda.is_available()}! :-)\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "# print(f\"PyTorch version: {torch.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3641d7f3-d562-4da6-a4a6-cf542c983ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Cuda available?: True! :-)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Is Cuda available?: {torch.cuda.is_available()}! :-)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd45675-7cbc-4c78-8113-564999ff16aa",
   "metadata": {},
   "source": [
    "# Training Loop (~24 min on first pass) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "391acc71-e856-4aea-b07b-4e863cf60a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Epoch #0 at 04:22 PM <3\n",
      "Batch 5 loaded at 04:22 PM! :-)\n",
      "Batch 10 loaded at 04:22 PM! :-)\n",
      "Batch 15 loaded at 04:22 PM! :-)\n",
      "Batch 20 loaded at 04:22 PM! :-)\n",
      "Batch 25 loaded at 04:22 PM! :-)\n",
      "Batch 30 loaded at 04:22 PM! :-)\n",
      "Batch 35 loaded at 04:22 PM! :-)\n",
      "Batch 40 loaded at 04:22 PM! :-)\n",
      "Batch 45 loaded at 04:22 PM! :-)\n",
      "Batch 50 loaded at 04:22 PM! :-)\n",
      "Batch 55 loaded at 04:22 PM! :-)\n",
      "Batch 60 loaded at 04:22 PM! :-)\n",
      "Batch 65 loaded at 04:22 PM! :-)\n",
      "Batch 70 loaded at 04:22 PM! :-)\n",
      "Batch 75 loaded at 04:22 PM! :-)\n",
      "Batch 80 loaded at 04:22 PM! :-)\n",
      "Batch 85 loaded at 04:22 PM! :-)\n",
      "Batch 90 loaded at 04:22 PM! :-)\n",
      "Batch 95 loaded at 04:22 PM! :-)\n",
      "Batch 100 loaded at 04:22 PM! :-)\n",
      "Batch 105 loaded at 04:22 PM! :-)\n",
      "Batch 110 loaded at 04:22 PM! :-)\n",
      "Batch 115 loaded at 04:22 PM! :-)\n",
      "Batch 120 loaded at 04:22 PM! :-)\n",
      "Batch 125 loaded at 04:22 PM! :-)\n",
      "Batch 130 loaded at 04:22 PM! :-)\n",
      "Batch 135 loaded at 04:22 PM! :-)\n",
      "Batch 140 loaded at 04:22 PM! :-)\n",
      "Batch 145 loaded at 04:22 PM! :-)\n",
      "Batch 150 loaded at 04:22 PM! :-)\n",
      "Batch 155 loaded at 04:22 PM! :-)\n",
      "Batch 160 loaded at 04:22 PM! :-)\n",
      "Training Epoch Complete\n",
      "Epoch 1/3, Training Loss: 0.9336\n",
      "Epoch 1/3, Validation Loss: 2.5748\n",
      "Starting Training Epoch #1 at 04:22 PM <3\n",
      "Batch 165 loaded at 04:22 PM! :-)\n",
      "Batch 170 loaded at 04:22 PM! :-)\n",
      "Batch 175 loaded at 04:22 PM! :-)\n",
      "Batch 180 loaded at 04:22 PM! :-)\n",
      "Batch 185 loaded at 04:22 PM! :-)\n",
      "Batch 190 loaded at 04:22 PM! :-)\n",
      "Batch 195 loaded at 04:23 PM! :-)\n",
      "Batch 200 loaded at 04:23 PM! :-)\n",
      "Batch 205 loaded at 04:23 PM! :-)\n",
      "Batch 210 loaded at 04:23 PM! :-)\n",
      "Batch 215 loaded at 04:23 PM! :-)\n",
      "Batch 220 loaded at 04:23 PM! :-)\n",
      "Batch 225 loaded at 04:23 PM! :-)\n",
      "Batch 230 loaded at 04:23 PM! :-)\n",
      "Batch 235 loaded at 04:23 PM! :-)\n",
      "Batch 240 loaded at 04:23 PM! :-)\n",
      "Batch 245 loaded at 04:23 PM! :-)\n",
      "Batch 250 loaded at 04:23 PM! :-)\n",
      "Batch 255 loaded at 04:23 PM! :-)\n",
      "Batch 260 loaded at 04:23 PM! :-)\n",
      "Batch 265 loaded at 04:23 PM! :-)\n",
      "Batch 270 loaded at 04:23 PM! :-)\n",
      "Batch 275 loaded at 04:23 PM! :-)\n",
      "Batch 280 loaded at 04:23 PM! :-)\n",
      "Batch 285 loaded at 04:23 PM! :-)\n",
      "Batch 290 loaded at 04:23 PM! :-)\n",
      "Batch 295 loaded at 04:23 PM! :-)\n",
      "Batch 300 loaded at 04:23 PM! :-)\n",
      "Batch 305 loaded at 04:23 PM! :-)\n",
      "Batch 310 loaded at 04:23 PM! :-)\n",
      "Batch 315 loaded at 04:23 PM! :-)\n",
      "Batch 320 loaded at 04:23 PM! :-)\n",
      "Batch 325 loaded at 04:23 PM! :-)\n",
      "Training Epoch Complete\n",
      "Epoch 2/3, Training Loss: 0.8618\n",
      "Epoch 2/3, Validation Loss: 2.5224\n",
      "Starting Training Epoch #2 at 04:23 PM <3\n",
      "Batch 330 loaded at 04:23 PM! :-)\n",
      "Batch 335 loaded at 04:23 PM! :-)\n",
      "Batch 340 loaded at 04:23 PM! :-)\n",
      "Batch 345 loaded at 04:23 PM! :-)\n",
      "Batch 350 loaded at 04:23 PM! :-)\n",
      "Batch 355 loaded at 04:23 PM! :-)\n",
      "Batch 360 loaded at 04:23 PM! :-)\n",
      "Batch 365 loaded at 04:23 PM! :-)\n",
      "Batch 370 loaded at 04:23 PM! :-)\n",
      "Batch 375 loaded at 04:23 PM! :-)\n",
      "Batch 380 loaded at 04:23 PM! :-)\n",
      "Batch 385 loaded at 04:23 PM! :-)\n",
      "Batch 390 loaded at 04:23 PM! :-)\n",
      "Batch 395 loaded at 04:23 PM! :-)\n",
      "Batch 400 loaded at 04:23 PM! :-)\n",
      "Batch 405 loaded at 04:23 PM! :-)\n",
      "Batch 410 loaded at 04:23 PM! :-)\n",
      "Batch 415 loaded at 04:23 PM! :-)\n",
      "Batch 420 loaded at 04:23 PM! :-)\n",
      "Batch 425 loaded at 04:23 PM! :-)\n",
      "Batch 430 loaded at 04:23 PM! :-)\n",
      "Batch 435 loaded at 04:23 PM! :-)\n",
      "Batch 440 loaded at 04:23 PM! :-)\n",
      "Batch 445 loaded at 04:23 PM! :-)\n",
      "Batch 450 loaded at 04:23 PM! :-)\n",
      "Batch 455 loaded at 04:23 PM! :-)\n",
      "Batch 460 loaded at 04:23 PM! :-)\n",
      "Batch 465 loaded at 04:23 PM! :-)\n",
      "Batch 470 loaded at 04:23 PM! :-)\n",
      "Batch 475 loaded at 04:23 PM! :-)\n",
      "Batch 480 loaded at 04:23 PM! :-)\n",
      "Batch 485 loaded at 04:23 PM! :-)\n",
      "Training Epoch Complete\n",
      "Epoch 3/3, Training Loss: 0.7924\n",
      "Epoch 3/3, Validation Loss: 2.4599\n"
     ]
    }
   ],
   "source": [
    "epochs = 3  # Number of training epochs. You can adjust this.\n",
    "batchcount = 0\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    current_loopTime = datetime.now().strftime('%I:%M %p') # This will give you time in the format '01:37 PM'\n",
    "    print(f\"Starting Training Epoch #{epoch} at {current_loopTime} <3\")\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Load batch to device\n",
    "        batchcount += 1\n",
    "        b_input_ids, b_input_mask, b_labels = batch[0].to(device), batch[1].to(device), batch[2].to(device)\n",
    "        current_batchTime = datetime.now().strftime('%I:%M %p')\n",
    "        if batchcount % 5 == 0:\n",
    "            print(f\"Batch {batchcount} loaded at {current_batchTime}! :-)\")\n",
    "        \n",
    "        # Clear out the gradients\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"Training Epoch Complete\")\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Training Loss: {avg_train_loss:.4f}\")\n",
    "    \n",
    "    # Start validation loop\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    val_total_loss = 0\n",
    "\n",
    "    for batch in val_dataloader:\n",
    "        # Move data to the device\n",
    "        b_input_ids, b_input_mask, b_labels = batch[0].to(device), batch[1].to(device), batch[2].to(device)\n",
    "\n",
    "        with torch.no_grad():  # Don't compute gradients for validation\n",
    "            outputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
    "            val_loss = outputs.loss\n",
    "            val_total_loss += val_loss.item()\n",
    "\n",
    "    val_avg_loss = val_total_loss / len(val_dataloader)\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Validation Loss: {val_avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73490bdc-bcf4-4e33-8fa1-6a8a0ae4a54e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Save the Model! :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8569f11b-ce6a-4b27-a3e2-67b96a0ebf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"GPU_v1_9-7-23-430pm.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea8cc1c-0ce9-49d5-8614-cdf5416e69a7",
   "metadata": {},
   "source": [
    "# Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d46aadc-88d2-4dc3-a248-f51428107f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {\n",
    "    'title': 0,\n",
    "    'placeholder': 1,\n",
    "    'mailbox': 2,\n",
    "    'non-english': 3,\n",
    "    'ownership': 4,\n",
    "    'error': 5\n",
    "}\n",
    "\n",
    "class_to_label_mapping = {v: k for k, v in label_dict.items()}\n",
    "\n",
    "new_titles = [\"After Hours MB\",\"A3B6C9D2\",\"Technical Queries MB\",\"Visual Designer II\",\"Agricultural Consultant\",\"Renewable Energy Consultant\",\"Product Development Manager\",\"Flight Operations Specialist\",\"Demo Job Role\",\"Blockchain Developer\",\"Data Analytics Specialist\",\"P3Q5R7S4\",\"Content Marketing Associate\",\"Client Relations Mailbox\",\"F4G7H1J5\",\"Technical Support Engineer\",\"Trade Show Manager\",\"K8L0M2N6\",\"Forensic Accountant\",\"Patient Care Coordinator\",\"V8W1X0Y9\",\"Title Not Listed\",\"Undefined Position\",\"Environmental Health Engineer\",\"Senior UX/UI Designer\",\"Social Media Analyst\",\"Benefits Management Mailbox\",\"Sales Support Mailbox\"]\n",
    "\n",
    "input_data = tokenizer(new_titles, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    predictions = model(**input_data)\n",
    "predicted_classes = torch.argmax(predictions.logits, dim=1)\n",
    "\n",
    "\n",
    "for title, class_idx in zip(new_titles, predicted_classes):\n",
    "    print(f\"Title: {title}\")\n",
    "    print(f\"Predicted Class: {class_to_label_mapping[class_idx.item()]}\")\n",
    "    print(\"-\" * 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc68dd76-89b1-4fb0-a8f8-19ada2024f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "dataloader = DataLoader(data, sampler=SequentialSampler(data), batch_size=batch_size)\n",
    "\n",
    "for i, (input_ids, attention_mask, true_labels) in enumerate(dataloader):\n",
    "    print(f\"Dataloader label for batch {i}: {true_labels}\")\n",
    "    print(f\"Original dataframe label for batch {i}: {df['class'].values[i*batch_size: (i+1)*batch_size]}\")\n",
    "    if i > 150:  # Print for the first 150 batches as an example, adjust as needed.\n",
    "        break\n",
    "\n",
    "\n",
    "all_predictions = []\n",
    "all_confidences = []\n",
    "all_true_labels = df['class'].values  # Get true labels from the dataframe\n",
    "titles = df['organizationalPerson.title'].values  # Get titles from the dataframe\n",
    "\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "last_print_time = start_time\n",
    "\n",
    "num_batches_processed = 0\n",
    "print_interval_minutes = 1\n",
    "\n",
    "# Randomly shuffle and pick 50 batches\n",
    "dataloader_batches = list(dataloader)\n",
    "#random.shuffle(dataloader_batches) # randomizer\n",
    "#sampled_batches = dataloader_batches[:50] #sampler\n",
    "sampled_batches = dataloader_batches\n",
    "\n",
    "print(\"Batches NOT shuffled and ALL selected. Starting to run predictions -\")\n",
    "\n",
    "for batch in sampled_batches:\n",
    "    input_ids, attention_mask, true_labels = batch\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        predictions = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    predicted_classes = torch.argmax(predictions.logits, dim=1)\n",
    "    all_predictions.extend(predicted_classes)\n",
    "\n",
    "    # Convert logits to probabilities\n",
    "    probabilities = F.softmax(predictions.logits, dim=1)\n",
    "    predicted_confidences = [prob[pred].item() for prob, pred in zip(probabilities, predicted_classes)]\n",
    "    all_confidences.extend(predicted_confidences)\n",
    "    \n",
    "    num_batches_processed += 1\n",
    "    current_time = datetime.datetime.now()\n",
    "    elapsed_since_last_print = (current_time - last_print_time).total_seconds() / 60  # Convert to minutes\n",
    "\n",
    "    if elapsed_since_last_print >= print_interval_minutes:\n",
    "        print(f\"It's now {current_time.strftime('%H:%M')}, {num_batches_processed} batches predicted.\")\n",
    "        last_print_time = current_time\n",
    "\n",
    "outliers = [(i, titles[i], all_predictions[i], all_true_labels[i], all_confidences[i]) for i in range(len(all_predictions)) if all_predictions[i] != all_true_labels[i]]\n",
    "\n",
    "# Display outliers\n",
    "print(\"Predictions Complete. Displaying Outliers:\")\n",
    "for i, title, pred, true, conf in outliers:\n",
    "    print(f\"Index: {i}\")\n",
    "    print(f\"Title: {title}\")\n",
    "    print(f\"Predicted Class: {class_to_label_mapping[pred.item()]} with confidence: {conf*100:.2f}%\")\n",
    "    print(f\"True Class: {class_to_label_mapping[true]}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ee4060-e16d-47e8-990d-6374ea5e3c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {\n",
    "    'title': 0,\n",
    "    'placeholder': 1,\n",
    "    'mailbox': 2,\n",
    "    'non-english': 3,\n",
    "    'ownership': 4,\n",
    "    'error': 5\n",
    "}\n",
    "\n",
    "class_to_label_mapping = {v: k for k, v in label_dict.items()}\n",
    "\n",
    "new_titles = [\"After Hours MB\",\"A3B6C9D2\",\"Technical Queries MB\",\"Visual Designer II\",\"Agricultural Consultant\",\"Renewable Energy Consultant\",\"Product Development Manager\",\"Flight Operations Specialist\",\"Demo Job Role\",\"Blockchain Developer\",\"Data Analytics Specialist\",\"P3Q5R7S4\",\"Content Marketing Associate\",\"Client Relations Mailbox\",\"F4G7H1J5\",\"Technical Support Engineer\",\"Trade Show Manager\",\"K8L0M2N6\",\"Forensic Accountant\",\"Patient Care Coordinator\",\"V8W1X0Y9\",\"Title Not Listed\",\"Undefined Position\",\"Environmental Health Engineer\",\"Senior UX/UI Designer\",\"Social Media Analyst\",\"Benefits Management Mailbox\",\"Sales Support Mailbox\"]\n",
    "\n",
    "input_data = tokenizer(new_titles, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    predictions = model(**input_data)\n",
    "predicted_classes = torch.argmax(predictions.logits, dim=1)\n",
    "\n",
    "\n",
    "for title, class_idx in zip(new_titles, predicted_classes):\n",
    "    print(f\"Title: {title}\")\n",
    "    print(f\"Predicted Class: {class_to_label_mapping[class_idx.item()]}\")\n",
    "    print(\"-\" * 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea4de23-2a2d-4d8f-8704-a556fb02d5e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
