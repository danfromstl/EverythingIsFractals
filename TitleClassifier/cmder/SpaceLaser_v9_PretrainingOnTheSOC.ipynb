{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24d63d98",
   "metadata": {},
   "source": [
    "# Space Laser v9 - Pretraining On The SOC Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd0ab7b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hooray! Here we go!\n"
     ]
    }
   ],
   "source": [
    "# Three Sections: (at the moment)\n",
    "# 1) Installation Commands\n",
    "# 2) Initialization Cells\n",
    "# 3) Training Loop\n",
    "\n",
    "print(\"Hooray! Here we go!\")\n",
    "\n",
    "# lolol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3970da",
   "metadata": {},
   "source": [
    "# Install Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb43696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidated\n",
    "conda install pandas scikit-learn transformers pytorch torchvision torchaudio cudatoolkit=11.8 -c pytorch -c conda-forge -c nvidia -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4d21e6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/r/win-64/current_repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/main/win-64/current_repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/main/noarch/current_repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/msys2/win-64/current_repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/msys2/noarch/current_repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/r/noarch/current_repodata.json HTTP/1.1\" 304 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conda install pandas -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee7face",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install scikit-learn -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0369eb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c conda-forge tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b54266",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3763128a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install transformers -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c627146d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install pytorch torchvision torchaudio cudatoolkit=11.8 -c pytorch -c nvidia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0154c29a",
   "metadata": {},
   "source": [
    "# Initialization Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ded0d45f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#CELL A: Load and Split the Data\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv(\"C://Offline_Storage//radiantClass//JobDesc_BlobText.csv\")\n",
    "\n",
    "# Split the data\n",
    "train, temp = train_test_split(data, test_size=0.1, random_state=42)\n",
    "val, test = train_test_split(temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40572cf0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#CELL B: Setting up the Model and Transformer\n",
    "\n",
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Data collator will help with constructing batches for training\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm_probability=0.15  # 15% of tokens will be masked for prediction\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86638468",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#CELL C: Tokenize the Data\n",
    "\n",
    "train_encodings = tokenizer(list(train['JobDesc_BlobText']), truncation=True, padding='max_length', max_length=512)\n",
    "val_encodings = tokenizer(list(val['JobDesc_BlobText']), truncation=True, padding='max_length', max_length=512)\n",
    "test_encodings = tokenizer(list(test['JobDesc_BlobText']), truncation=True, padding='max_length', max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f50817f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#CELL D: Convert to Dataset and DataLoader\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class JobTitleDataset(Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: val[idx] for key, val in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)\n",
    "\n",
    "train_dataset = JobTitleDataset(train_encodings)\n",
    "val_dataset = JobTitleDataset(val_encodings)\n",
    "test_dataset = JobTitleDataset(test_encodings)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=8, collate_fn=data_collator)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c38faabd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#CELL E: Training Setup and Device Configuration\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "\n",
    "# Check for CUDA and move the model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Setup optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8605aa3d-fa15-4cad-b178-44d40bba40b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Cuda available?: False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"Is Cuda available?: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40d2f2e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Cuda available?: False! :-)\n",
      "CUDA version: None\n"
     ]
    }
   ],
   "source": [
    "#CELL F: Verify that CUDA is available\n",
    "\n",
    "print(f\"Is Cuda available?: {torch.cuda.is_available()}! :-)\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0e070f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CELL Proto-G:\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c839e457",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CELL G: Set Up TensorBoard within the Notebook\n",
    "\n",
    "%tensorboard --logdir ./logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc8f10f",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e09c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CELL H: Model Training Using Trainer\n",
    "\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    per_device_train_batch_size=8,  # Adjust batch size based on your GPU/CPU capacity\n",
    "    per_device_eval_batch_size=8,  # Same for validation batch size\n",
    "    num_train_epochs=3,  # Adjust the number of epochs based on your needs\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    save_strategy=\"epoch\",  # Save only the best model based on validation loss\n",
    "    load_best_model_at_end=True,  # Load the best model at the end of training\n",
    "    push_to_hub=False,  # Disable model hub push\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator  # Use the data_collator from CELL B\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa3dcd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
